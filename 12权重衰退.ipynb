{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d4dcde3-ffff-4979-a764-5d9ed9f27645",
   "metadata": {},
   "source": [
    "# 权重衰退（Weight Decay）——防止过拟合的第一招\n",
    "\n",
    "---\n",
    "\n",
    "## 一、核心一句话\n",
    "\n",
    "> **权重衰退 = 惩罚权重太大，让模型别太\"聪明\"，防止过拟合。**\n",
    "\n",
    "---\n",
    "\n",
    "## 二、为什么需要权重衰退？\n",
    "\n",
    "### 回顾上一节的过拟合\n",
    "\n",
    "```\n",
    "过拟合 = 模型把噪声也学进去了\n",
    "       = 权重 w 调得太\"精细\"了\n",
    "\n",
    "例子：\n",
    "  真实规律：w = [5, 1.2, -3.4, 5.6, 0, 0, ..., 0]\n",
    "                 ↑   ↑    ↑     ↑   ↑→ 应该是 0\n",
    "  \n",
    "  过拟合后：w = [5, 1.2, -3.4, 5.6, 0.8, -0.3, ..., -0.5]\n",
    "                                     ↑→ 不该有值，但模型学出来了\n",
    "```\n",
    "\n",
    "**怎么解决？**\n",
    "\n",
    "```\n",
    "方案1：减少参数数量（用更小的模型）\n",
    "       → 但可能会欠拟合\n",
    "\n",
    "方案2：限制每个参数的值不要太大\n",
    "       → 权重衰退就是这个！\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 三、权重衰退理解方式\n",
    "\n",
    "### 方式 2：柔性限制（实际用的）\n",
    "\n",
    "```\n",
    "不直接限制 w 的大小\n",
    "而是在损失函数里加一个\"惩罚项\"：\n",
    "\n",
    "新的损失函数 = 原损失 + λ/2 ||w||²\n",
    "              ↑         ↑\n",
    "            老的       惩罚项\n",
    "            \n",
    "L_new = L(w, b) + λ/2 ||w||²\n",
    "```\n",
    "\n",
    "**什么意思？**\n",
    "\n",
    "```\n",
    "原来：只管让预测准确（L 小）\n",
    "现在：既要预测准确，又要 w 不能太大\n",
    "\n",
    "如果 w 太大：\n",
    "  → ||w||² 很大\n",
    "  → L_new 变大\n",
    "  → 模型不愿意让 w 太大\n",
    "  \n",
    "λ（lambda）控制惩罚强度：\n",
    "  λ = 0   → 没有惩罚，等于没加权重衰退\n",
    "  λ 很大  → 惩罚很重，w 会被压得很小\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 五、用图理解权重衰退的作用\n",
    "\n",
    "### 没有权重衰退\n",
    "\n",
    "```\n",
    "损失函数 L 的等高线（俯视图）：\n",
    "\n",
    "        ╭──────╮\n",
    "       ╱        ╲\n",
    "      │    ★    │  ← 最优点（w 可能很大）\n",
    "       ╲        ╱\n",
    "        ╰──────╯\n",
    "```\n",
    "\n",
    "### 有权重衰退\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 六、代码怎么用？\n",
    "\n",
    "### 写法 2：用 PyTorch 的 `weight_decay`（推荐）\n",
    "\n",
    "```python\n",
    "# 在优化器里直接指定\n",
    "trainer = torch.optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=0.01,\n",
    "    weight_decay=0.01  # ← 就这一个参数！\n",
    ")\n",
    "\n",
    "# 训练时正常写\n",
    "for X, y in train_iter:\n",
    "    l = loss(net(X), y)  # 不用手动加惩罚项\n",
    "    trainer.zero_grad()\n",
    "    l.backward()\n",
    "    trainer.step()       # 更新时自动做权重衰退\n",
    "```\n",
    "\n",
    "**PyTorch 会自动帮你：**\n",
    "```\n",
    "在梯度下降时，自动执行：\n",
    "  w = (1 - η×weight_decay) × w - η × ∂L/∂w\n",
    "  \n",
    "你只需要设置 weight_decay 这个参数！\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 七、λ（lambda / weight_decay）怎么选？\n",
    "\n",
    "```\n",
    "λ = 0      → 没有权重衰退，可能过拟合\n",
    "λ = 0.0001 → 很轻的惩罚\n",
    "λ = 0.001  → 轻度惩罚（常用）\n",
    "λ = 0.01   → 中度惩罚（常用）\n",
    "λ = 0.1    → 重度惩罚\n",
    "λ 很大     → w 被压得太小，可能欠拟合\n",
    "```\n",
    "\n",
    "**实际怎么选？**\n",
    "\n",
    "```\n",
    "和隐藏层大小、学习率一样，靠试！\n",
    "\n",
    "常见策略：\n",
    "  先不加权重衰退（λ=0）训练一次\n",
    "  → 如果过拟合了（训练精度>>测试精度）\n",
    "  → 加上权重衰退，λ 从 0.001 开始试\n",
    "  → 看测试精度有没有提升\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 八、你需要掌握的\n",
    "\n",
    "### 🔴 必须记住\n",
    "\n",
    "**① 权重衰退是干什么的**\n",
    "\n",
    "```\n",
    "防止权重 w 太大\n",
    "防止过拟合\n",
    "```\n",
    "\n",
    "**② 怎么用**\n",
    "\n",
    "```python\n",
    "trainer = torch.optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=0.01,\n",
    "    weight_decay=0.01  # ← 加这一行\n",
    ")\n",
    "```\n",
    "\n",
    "**③ λ 的作用**\n",
    "\n",
    "```\n",
    "λ = 0       → 没有权重衰退\n",
    "λ 越大      → 惩罚越重，w 越小\n",
    "λ 太大      → 可能欠拟合\n",
    "```\n",
    "\n",
    "**④ 为什么叫\"衰退\"**\n",
    "\n",
    "```\n",
    "每次更新前，先把 w 缩小一点点\n",
    "w_new = (1 - ηλ) × w_old - ...\n",
    "        ↑\n",
    "      小于1，所以是\"衰退\"\n",
    "```\n",
    "\n",
    "\n",
    "## 九、自查题\n",
    "\n",
    "```\n",
    "① 权重衰退是防止什么的？\n",
    "   → 过拟合（权重太大）\n",
    "\n",
    "② PyTorch 里怎么加权重衰退？\n",
    "   → 优化器里设置 weight_decay 参数\n",
    "\n",
    "③ weight_decay = 0 是什么意思？\n",
    "   → 没有权重衰退\n",
    "\n",
    "④ weight_decay 太大会怎样？\n",
    "   → w 被压得太小，可能欠拟合\n",
    "\n",
    "⑤ 为什么叫\"衰退\"？\n",
    "   → 每次更新前先把 w 缩小一点\n",
    "```\n",
    "\n",
    "**5 个都对 → 过关！**\n",
    "\n",
    "---\n",
    "\n",
    "## 十、总结\n",
    "\n",
    "```\n",
    "防止过拟合的第一招：权重衰退\n",
    "\n",
    "原理：\n",
    "  在损失函数里加惩罚项 λ/2 ||w||²\n",
    "  → 让模型不敢把 w 调太大\n",
    "  \n",
    "效果：\n",
    "  每次更新前先把 w 缩小一点\n",
    "  → w 变小\n",
    "  → 模型变简单\n",
    "  → 不容易过拟合\n",
    "  \n",
    "用法：\n",
    "  优化器里加一个 weight_decay 参数\n",
    "  常用值：0.001 ~ 0.01\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab83c75-9ca7-49d7-8c28-bc6688ae07bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
