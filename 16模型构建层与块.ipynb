{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d595ab-eb7e-4797-b137-5821c5da0046",
   "metadata": {},
   "source": [
    "# ⭐⭐⭐模型构造：层与块\n",
    "\n",
    "**基础回顾非常重要**\n",
    "\n",
    "---\n",
    "\n",
    "## 一、神经网络到底在干什么？\n",
    "\n",
    "```\n",
    "数据进来 → 经过第1层 → 经过第2层 → 经过第3层 → 结果出来\n",
    "```\n",
    "\n",
    "\n",
    "## 二、Python基础再rev\n",
    "\n",
    "### 类class：一张图纸\n",
    "\n",
    "```python\n",
    "# \"类\"就是一个模板/图纸\n",
    "class Dog:\n",
    "    def __init__(self, name):      # 造狗时要做的准备\n",
    "        self.name = name           # 把名字记住（绑在自己身上）\n",
    "    \n",
    "    def bark(self):                # 狗会叫\n",
    "        print(\"你好，我是\" + self.name)\n",
    "\n",
    "# 用图纸造一只真狗\n",
    "my_dog = Dog(\"旺财\")\n",
    "my_dog.bark()                      # 输出：你好，我是旺财\n",
    "```\n",
    "\n",
    "| 概念 | 意思 | 比喻 |\n",
    "|:---|:---|:---|\n",
    "| `class` | 定义一个模板 | 画图纸 |\n",
    "| `__init__` | 造东西时要做的准备初始化 | 买材料 |\n",
    "| `self` | \"我自己\" | 指代这只狗自己 |\n",
    "| `self.name` | 我自己的名字 | 这只狗记住自己叫什么 |\n",
    "| `Dog(\"旺财\")` | 用模板造一个实际的东西 | 按图纸造一只真狗 |\n",
    "\n",
    "---\n",
    "\n",
    "## 三、搞懂 self\n",
    "\n",
    "### 3.1 self = \"我自己的\"\n",
    "\n",
    "```python\n",
    "self.hidden = nn.Linear(20, 256)\n",
    "# 意思：我自己的hidden层 = 一个吃20吐256的机器\n",
    "```\n",
    "\n",
    "### 3.2 为什么需要self？\n",
    "\n",
    "```python\n",
    "# ❌ 没有self\n",
    "def __init__(self):\n",
    "    hidden = nn.Linear(20, 256)    # 临时变量，函数结束就没了\n",
    "\n",
    "def forward(self, X):\n",
    "    X = hidden(X)                  # 报错！hidden已经消失了！\n",
    "```\n",
    "\n",
    "```python\n",
    "# ✅ 有self\n",
    "def __init__(self):\n",
    "    self.hidden = nn.Linear(20, 256)    # 绑在自己身上，一直在\n",
    "\n",
    "def forward(self, X):\n",
    "    X = self.hidden(X)                  # 能找到！因为绑在身上\n",
    "```\n",
    "\n",
    "**生活比喻：**\n",
    "\n",
    "```\n",
    "没有self → 在商店买了菜刀，放在门口就走了 → 回家做菜时找不到\n",
    "有self   → 买了菜刀带回家了 → 随时能用\n",
    "```\n",
    "\n",
    "### 3.3 核心规则\n",
    "\n",
    "**init里用self存东西，forward里用self取东西，名字必须对应！**\n",
    "\n",
    "```python\n",
    "# ✅ 名字对应\n",
    "self.aaa = nn.Linear(20, 256)     # init里叫aaa\n",
    "X = self.aaa(X)                    # forward里也叫aaa\n",
    "\n",
    "# ❌ 名字不对应\n",
    "self.aaa = nn.Linear(20, 256)     # init里叫aaa\n",
    "X = self.bbb(X)                    # 报错！没有bbb这个东西！\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 四、搞懂 nn.Linear\n",
    "\n",
    "### 4.1 它是一台\"加工机器\"\n",
    "\n",
    "```python\n",
    "machine = nn.Linear(20, 256)\n",
    "```\n",
    "\n",
    "```\n",
    "我造了一台机器\n",
    "    吃 20 个数字（输入维度）\n",
    "    吐 256 个数字（输出维度）\n",
    "我给它起名叫 machine\n",
    "```\n",
    "\n",
    "**机器被造出来时，PyTorch自动在里面放好了随机的权重，你不需要手动设置。**\n",
    "\n",
    "### 4.2 数字必须前后对应\n",
    "\n",
    "**前一层的输出 = 后一层的输入，就像水管接水管：**\n",
    "\n",
    "```\n",
    "你的数据\n",
    "[20个数] ← 输入\n",
    "\n",
    "    ↓  nn.Linear(20, 256)      20进，256出\n",
    "\n",
    "[256个数]\n",
    "\n",
    "    ↓  nn.Linear(256, 10)      256进，10出\n",
    "                                这个256必须=上面的256！\n",
    "\n",
    "[10个数] ← 最终输出\n",
    "```\n",
    "\n",
    "```\n",
    "如果不匹配：\n",
    "machine1 吐出 256 个数\n",
    "machine2 只能吃 100 个数\n",
    "→ 报错！塞不进去！就像粗水管接细水管，接不上！\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 五、搞懂 F\n",
    "\n",
    "### 5.1 F是什么？\n",
    "\n",
    "```python\n",
    "from torch.nn import functional as F\n",
    "```\n",
    "\n",
    "**F就是一个装满现成函数的工具包，起名叫F只是为了少打字。**\n",
    "\n",
    "```\n",
    "F.relu()       → ReLU激活函数（负数变0）\n",
    "F.sigmoid()    → Sigmoid函数\n",
    "F.softmax()    → Softmax函数\n",
    "```\n",
    "\n",
    "### 5.2 F.relu vs nn.ReLU\n",
    "\n",
    "```\n",
    "F.relu(X)     → 直接说\"帮我切菜\"        → 一个动作\n",
    "nn.ReLU()     → 先买把菜刀放厨房再切     → 一个东西\n",
    "```\n",
    "\n",
    "**结果完全一样！ReLU没有要学习的参数，所以用F.relu更省事。**\n",
    "\n",
    "**简单规则：**\n",
    "\n",
    "| 情况 | 用什么 | 例子 |\n",
    "|:---|:---|:---|\n",
    "| 有参数要学习的层 | nn.XXX | nn.Linear |\n",
    "| 没参数的纯计算 | F.xxx | F.relu |\n",
    "\n",
    "---\n",
    "\n",
    "## 六、哪些能改，哪些不能改\n",
    "\n",
    "```python\n",
    "class MLP(nn.Module):\n",
    "#     ^^^ 你起的名字 ✅能改     \n",
    "#          nn.Module  ❌不能改（PyTorch规定）\n",
    "\n",
    "    def __init__(self):          # __init__ ❌不能改（Python规定）\n",
    "        super().__init__()       # ❌不能改（固定写法）\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "#            ^^^^^^ 你起的名字 ✅能改\n",
    "#                    nn.Linear ❌不能改（PyTorch提供的层）\n",
    "#                              ^^ ^^^ 数字 ✅根据需要改\n",
    "    \n",
    "    def forward(self, X):        # forward ❌不能改（PyTorch规定）\n",
    "#                     ^ 你起的名字 ✅能改\n",
    "        X = self.hidden(X)\n",
    "#            ^^^^^^ 必须和init里的名字对应！\n",
    "        X = F.relu(X)            # F.relu ❌不能改（PyTorch提供的函数）\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 七、两种构造方式\n",
    "\n",
    "### 7.1 方式一：Sequential（简单版）\n",
    "\n",
    "**像坐地铁：只能按站走，不能拐弯。**\n",
    "\n",
    "```python\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(20, 256),    # 第1站\n",
    "    nn.ReLU(),             # 第2站\n",
    "    nn.Linear(256, 10)     # 第3站\n",
    ")\n",
    "\n",
    "X = torch.rand(2, 20)     # 造2个样本，每个20个特征\n",
    "output = net(X)            # 丢进去，自动按顺序走\n",
    "```\n",
    "\n",
    "### 7.2 方式二：自定义类（灵活版）\n",
    "\n",
    "**像自己开车：想怎么走就怎么走。**\n",
    "\n",
    "```python\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):     # 我有哪些零件\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, X):   # 数据怎么走\n",
    "        X = self.hidden(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.out(X)\n",
    "        return X\n",
    "\n",
    "net = MLP()      # 造网络【实例化】\n",
    "output = net(X)    # 丢数据（自动调用forward）\n",
    "```\n",
    "\n",
    "### 7.3 什么时候用哪个？\n",
    "\n",
    "| 场景 | 用什么 |\n",
    "|:---|:---|\n",
    "| 简单的一层接一层 | Sequential，省事 |\n",
    "| 需要if判断、循环、分支等 | 自定义类 |\n",
    "\n",
    "---\n",
    "\n",
    "## 八、nn.Module 是一切的基础\n",
    "\n",
    "```\n",
    "nn.Linear      → 是 nn.Module 的子类\n",
    "nn.ReLU        → 是 nn.Module 的子类  \n",
    "nn.Sequential  → 是 nn.Module 的子类\n",
    "你自定义的MLP   → 也是 nn.Module 的子类\n",
    "```\n",
    "\n",
    "**都是同一个接口，所以可以像乐高一样随意拼接嵌套：**\n",
    "\n",
    "```python\n",
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()#必须写！！！\n",
    "        self.net = nn.Sequential(  # 里面放Sequential\n",
    "            nn.Linear(20, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.linear = nn.Linear(32, 16)  # 再加一个单独的层\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))   # 先过net再过linear\n",
    "        # 一定⭐⭐注意执行顺序前向传播由内向外的顺序！\n",
    "```\n",
    "\n",
    "**大盒子里放小盒子，小盒子里还能放更小的盒子。**\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 十、完整代码逐行翻译\n",
    "\n",
    "```python\n",
    "import torch                            # 导入PyTorch工具箱\n",
    "from torch import nn                    # 拿出神经网络工具\n",
    "from torch.nn import functional as F    # 拿出函数工具包，叫F\n",
    "\n",
    "class MLP(nn.Module):                   # 画图纸，叫MLP\n",
    "\n",
    "    def __init__(self):                 # 准备工作\n",
    "        super().__init__()              # PyTorch自己的准备（固定写法）\n",
    "        self.hidden = nn.Linear(20, 256)  # 绑一台机器：吃20吐256\n",
    "        self.out = nn.Linear(256, 10)     # 绑一台机器：吃256吐10\n",
    "\n",
    "    def forward(self, X):               # 数据怎么走\n",
    "        X = self.hidden(X)              # X过hidden层：20→256\n",
    "        X = F.relu(X)                   # 负数变0\n",
    "        X = self.out(X)                 # X过out层：256→10\n",
    "        return X                        # 吐出结果\n",
    "\n",
    "net = MLP()                             # 按图纸造网络\n",
    "X = torch.rand(2, 20)                   # 造数据：2个样本×20特征\n",
    "output = net(X)                         # 丢进网络，输出2×10\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 终极总结：三句话记住一切\n",
    "\n",
    "```\n",
    "1. __init__ 里：用self绑好所有的层（\"我有哪些零件\"）\n",
    "2. forward 里：用self取出层，定义数据怎么走（\"数据怎么流动\"）\n",
    "3. 反向传播不用管，PyTorch自动搞定\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c1f6e-1eca-4fae-9089-e46513062ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
