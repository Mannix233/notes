{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13a94ff-538b-4694-9368-299ca0a4735f",
   "metadata": {},
   "source": [
    "# 卷积层代码实现：\n",
    "\n",
    "---\n",
    "\n",
    "## 一、手动实现互相关运算（理解原理）\n",
    "\n",
    "### 代码\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "def corr2d(X, K):\n",
    "    \"\"\"X是输入，K是卷积核\"\"\"\n",
    "    h, w = K.shape                              # 拿到卷积核的高和宽\n",
    "    Y = torch.zeros((X.shape[0] - h + 1,        # 输出的高\n",
    "                      X.shape[1] - w + 1))       # 输出的宽\n",
    "    for i in range(Y.shape[0]):                  # 遍历输出的每一行\n",
    "        for j in range(Y.shape[1]):              # 遍历输出的每一列\n",
    "            Y[i, j] = (X[i:i+h, j:j+w] * K).sum()  # 取小块 × 核，求和\n",
    "    return Y\n",
    "```\n",
    "\n",
    "### 逐行翻译\n",
    "\n",
    "```python\n",
    "h, w = K.shape\n",
    "```\n",
    "\n",
    "```\n",
    "卷积核K是一个小矩阵，比如2×2\n",
    "h = 2（高）\n",
    "w = 2（宽）\n",
    "\n",
    "这行就是：看看卷积核多大\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "```\n",
    "\n",
    "```\n",
    "创建一个全是0的输出矩阵\n",
    "\n",
    "输出的大小怎么算？\n",
    "    输出高 = 输入高 - 核高 + 1\n",
    "    输出宽 = 输入宽 - 核宽 + 1\n",
    "\n",
    "比如输入3×3，核2×2：\n",
    "    输出高 = 3 - 2 + 1 = 2\n",
    "    输出宽 = 3 - 2 + 1 = 2\n",
    "    所以输出是2×2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "for i in range(Y.shape[0]):\n",
    "    for j in range(Y.shape[1]):\n",
    "```\n",
    "\n",
    "```\n",
    "两个循环：遍历输出矩阵的每个位置\n",
    "\n",
    "输出是2×2的话：\n",
    "    i=0, j=0 → 左上角\n",
    "    i=0, j=1 → 右上角\n",
    "    i=1, j=0 → 左下角\n",
    "    i=1, j=1 → 右下角\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "Y[i, j] = (X[i:i+h, j:j+w] * K).sum()\n",
    "```\n",
    "\n",
    "**这是最核心的一行！拆开看：**\n",
    "\n",
    "```\n",
    "X[i:i+h, j:j+w]\n",
    "→ 从输入X中取出一个和卷积核一样大的小块\n",
    "→ 从第i行到第i+h行，从第j列到第j+w列\n",
    "\n",
    "举例：i=0, j=0, h=2, w=2\n",
    "    X[0:2, 0:2] 就是左上角的2×2小块\n",
    "```\n",
    "\n",
    "```\n",
    "X[i:i+h, j:j+w] * K\n",
    "→ 小块和卷积核对应位置相乘（不是矩阵乘法！是逐个元素相乘）\n",
    "\n",
    "小块：[0, 1]    卷积核：[0, 1]    相乘：[0×0, 1×1]   [0, 1]\n",
    "      [3, 4]            [2, 3]          [3×2, 4×3] = [6, 12]\n",
    "```\n",
    "\n",
    "```\n",
    ".sum()\n",
    "→ 把所有结果加起来\n",
    "→ 0 + 1 + 6 + 12 = 19\n",
    "\n",
    "Y[0, 0] = 19\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 验证一下\n",
    "\n",
    "```python\n",
    "X = torch.tensor([[0.0, 1, 2],\n",
    "                   [3, 4, 5],\n",
    "                   [6, 7, 8]])\n",
    "\n",
    "K = torch.tensor([[0.0, 1],\n",
    "                   [2, 3]])\n",
    "\n",
    "print(corr2d(X, K))\n",
    "# 输出：tensor([[19., 25.],\n",
    "#               [37., 43.]])\n",
    "```\n",
    "\n",
    "**和我们手算的结果一样！**\n",
    "\n",
    "---\n",
    "\n",
    "## 二、用这个运算构建卷积层\n",
    "\n",
    "### 代码\n",
    "\n",
    "```python\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return corr2d(X, self.weight) + self.bias\n",
    "```\n",
    "\n",
    "### 逐行翻译\n",
    "\n",
    "```python\n",
    "class Conv2D(nn.Module):\n",
    "```\n",
    "\n",
    "```\n",
    "定义一个卷积层，名字叫Conv2D\n",
    "继承nn.Module（和之前学的一样）\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "def __init__(self, kernel_size):\n",
    "```\n",
    "\n",
    "```\n",
    "准备工作：需要告诉我卷积核多大\n",
    "\n",
    "kernel_size就是核的大小\n",
    "比如传入 (2, 2) 就是2×2的核\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "```\n",
    "\n",
    "```\n",
    "torch.rand(kernel_size)  → 生成一个随机矩阵（比如2×2的随机数）\n",
    "nn.Parameter(...)        → 告诉PyTorch：这是可学习的参数！要训练它！\n",
    "self.weight = ...        → 绑在自己身上，叫weight\n",
    "\n",
    "这就是卷积核！初始值是随机的，训练会调整它\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "self.bias = nn.Parameter(torch.zeros(1))\n",
    "```\n",
    "\n",
    "```\n",
    "偏置，初始为0\n",
    "也是可学习的参数\n",
    "就是一个数字，加到输出上\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "def forward(self, X):\n",
    "    return corr2d(X, self.weight) + self.bias\n",
    "```\n",
    "\n",
    "```\n",
    "数据怎么走：\n",
    "    把输入X和自己的卷积核(self.weight)做互相关运算\n",
    "    再加上偏置(self.bias)\n",
    "    返回结果\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 三、边缘检测的例子\n",
    "\n",
    "### 3.1 构造一个简单的输入\n",
    "\n",
    "```python\n",
    "X = torch.ones(6, 8)       # 6×8的全1矩阵\n",
    "X[:, 2:6] = 0              # 中间4列设为0\n",
    "print(X)\n",
    "```\n",
    "\n",
    "```\n",
    "输出：\n",
    "1  1  0  0  0  0  1  1\n",
    "1  1  0  0  0  0  1  1\n",
    "1  1  0  0  0  0  1  1\n",
    "1  1  0  0  0  0  1  1\n",
    "1  1  0  0  0  0  1  1\n",
    "1  1  0  0  0  0  1  1\n",
    "\n",
    "左边两列是1，中间四列是0，右边两列是1\n",
    "在第2列和第3列之间有一条\"边缘\"（从白变黑）\n",
    "在第5列和第6列之间有一条\"边缘\"（从黑变白）\n",
    "```\n",
    "\n",
    "### 3.2 构造一个边缘检测核\n",
    "\n",
    "```python\n",
    "K = torch.tensor([[1.0, -1.0]])    # 1×2的核\n",
    "```\n",
    "\n",
    "**这个核为什么能检测边缘？**\n",
    "\n",
    "```\n",
    "核是 [1, -1]\n",
    "\n",
    "当窗口盖住两个相同的像素时：\n",
    "    [1, 1] × [1, -1] = 1×1 + 1×(-1) = 0    ← 没有边缘\n",
    "    [0, 0] × [1, -1] = 0×1 + 0×(-1) = 0    ← 没有边缘\n",
    "\n",
    "当窗口盖住两个不同的像素时：\n",
    "    [1, 0] × [1, -1] = 1×1 + 0×(-1) = 1    ← 检测到边缘！\n",
    "    [0, 1] × [1, -1] = 0×1 + 1×(-1) = -1   ← 检测到边缘！\n",
    "\n",
    "相同 → 输出0（没边缘）\n",
    "不同 → 输出非0（有边缘！）\n",
    "```\n",
    "\n",
    "### 3.3 做卷积\n",
    "\n",
    "```python\n",
    "Y = corr2d(X, K)\n",
    "print(Y)\n",
    "```\n",
    "\n",
    "```\n",
    "输出：\n",
    " 0   1  0  0  0 -1  0\n",
    " 0   1  0  0  0 -1  0\n",
    " 0   1  0  0  0 -1  0\n",
    " 0   1  0  0  0 -1  0\n",
    " 0   1  0  0  0 -1  0\n",
    " 0   1  0  0  0 -1  0\n",
    "\n",
    "1的那一列 = 从白变黑的边缘\n",
    "-1的那一列 = 从黑变白的边缘\n",
    "0 = 没有边缘\n",
    "```\n",
    "\n",
    "**卷积成功检测出了竖直方向的边缘！**\n",
    "\n",
    "---\n",
    "\n",
    "## 四、用梯度下降学习卷积核\n",
    "\n",
    "### 场景\n",
    "\n",
    "```\n",
    "现在假装你不知道K是[1, -1]\n",
    "你只知道输入X和输出Y\n",
    "问：能不能通过训练学出K？\n",
    "```\n",
    "\n",
    "### 代码\n",
    "\n",
    "```python\n",
    "# 用PyTorch自带的Conv2d\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)\n",
    "```\n",
    "\n",
    "**参数解释：**\n",
    "\n",
    "```\n",
    "nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)\n",
    "          ^  ^              ^^^^^        ^^^^^\n",
    "          |  |              核大小       不要偏置\n",
    "          |  输出通道数=1\n",
    "          输入通道数=1\n",
    "\n",
    "现在只有1个输入1个输出（黑白图片）\n",
    "核大小1×2（和我们手动构造的一样）\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# 把X和Y变成4维（PyTorch要求的格式）\n",
    "X = X.reshape((1, 1, 6, 8))    # 1个样本，1个通道，6行8列\n",
    "Y = Y.reshape((1, 1, 6, 7))    # 输出也要reshape\n",
    "```\n",
    "\n",
    "**为什么要4维？**\n",
    "\n",
    "```\n",
    "PyTorch的Conv2d要求输入必须是4维：\n",
    "(批量大小, 通道数, 高, 宽)\n",
    "\n",
    "我们就1张图，1个通道\n",
    "所以前面加两个1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# 训练10轮\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)                    # 用当前的核算输出\n",
    "    loss = (Y_hat - Y) ** 2              # 算误差\n",
    "    conv2d.zero_grad()                   # 清零梯度\n",
    "    loss.sum().backward()                # 反向传播\n",
    "    conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad   # 更新权重\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'第{i+1}轮, loss={loss.sum():.3f}')\n",
    "```\n",
    "\n",
    "### 逐行翻译\n",
    "\n",
    "```python\n",
    "Y_hat = conv2d(X)\n",
    "```\n",
    "\n",
    "```\n",
    "把X丢进卷积层，用当前的（随机的）核算出结果\n",
    "Y_hat是预测值\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "loss = (Y_hat - Y) ** 2\n",
    "```\n",
    "\n",
    "```\n",
    "预测值 - 真实值，然后平方\n",
    "平方是为了让误差都变正数\n",
    "loss越小说明核越接近正确答案\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "conv2d.zero_grad()\n",
    "```\n",
    "\n",
    "```\n",
    "清零之前的梯度\n",
    "每次算新梯度之前必须清零（PyTorch的规矩）\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "loss.sum().backward()\n",
    "```\n",
    "\n",
    "```\n",
    ".sum() → 把所有误差加起来变成一个数\n",
    ".backward() → 反向传播，算出梯度\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad\n",
    "```\n",
    "\n",
    "```\n",
    "手动更新权重（梯度下降）\n",
    "\n",
    "conv2d.weight.data  → 当前的核的值\n",
    "conv2d.weight.grad  → 核的梯度（该往哪个方向调）\n",
    "3e-2 = 0.03         → 学习率（每次调多少）\n",
    "\n",
    "新权重 = 旧权重 - 学习率 × 梯度\n",
    "```\n",
    "\n",
    "### 最终结果\n",
    "\n",
    "```python\n",
    "print(conv2d.weight.data.reshape((1, 2)))\n",
    "# 输出：tensor([[ 0.99, -0.99]])\n",
    "```\n",
    "\n",
    "**学出来的核接近 [1, -1]，和我们手动构造的几乎一样！**\n",
    "\n",
    "```\n",
    "我们构造的：   [1.0,  -1.0]\n",
    "学出来的：     [0.99, -0.99]\n",
    "\n",
    "非常接近！说明网络通过训练自己学会了边缘检测\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 五、总结\n",
    "\n",
    "### 你需要记住的\n",
    "\n",
    "```\n",
    "1. 卷积运算 = 小窗口滑动，对应位置相乘再求和\n",
    "2. 输出大小 = 输入大小 - 核大小 + 1\n",
    "3. 卷积核是可学习的参数，不需要手动设计\n",
    "4. PyTorch的Conv2d输入必须是4维：(批量, 通道, 高, 宽)\n",
    "```\n",
    "\n",
    "### 使用PyTorch自带的Conv2d\n",
    "\n",
    "```python\n",
    "# 实际中直接用这个就行，不需要自己写corr2d\n",
    "conv_layer = nn.Conv2d(\n",
    "    in_channels=1,        # 输入通道数\n",
    "    out_channels=1,       # 输出通道数\n",
    "    kernel_size=(3, 3),   # 卷积核大小\n",
    "    bias=False            # 要不要偏置\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db21169-bcb1-4246-b784-4efe02116387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
